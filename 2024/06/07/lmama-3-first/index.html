<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【微调大模型llama】 基于llama 3利用自己的数据集微调（1） | CARRY</title><meta name="author" content="CARRY"><meta name="copyright" content="CARRY"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="referrer" content="no-referrer"><meta name="description" content="Llama 3介绍本次Llama-3的介绍与前两个版本差不多，大量的测试数据和格式化介绍。但Meta特意提到Llama-3使用了掩码和分组查询注意力这两项技术。 目前，大模型领域最流行的Transformer架构的核心功能是自我注意力机制，这是一种用于处理序列数据的技术，可对输入序列中的每个元素进行加权聚合，以捕获元素之间的重要关系。   新的 8B 和 70B 参数 Llama 3 模型是 Ll">
<meta property="og:type" content="article">
<meta property="og:title" content="【微调大模型llama】 基于llama 3利用自己的数据集微调（1）">
<meta property="og:url" content="https://delahayecarry.github.io/2024/06/07/lmama-3-first/index.html">
<meta property="og:site_name" content="CARRY">
<meta property="og:description" content="Llama 3介绍本次Llama-3的介绍与前两个版本差不多，大量的测试数据和格式化介绍。但Meta特意提到Llama-3使用了掩码和分组查询注意力这两项技术。 目前，大模型领域最流行的Transformer架构的核心功能是自我注意力机制，这是一种用于处理序列数据的技术，可对输入序列中的每个元素进行加权聚合，以捕获元素之间的重要关系。   新的 8B 和 70B 参数 Llama 3 模型是 Ll">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/carry121/pictures/raw/master//pictures/20240607235739.png">
<meta property="article:published_time" content="2024-06-07T14:24:09.000Z">
<meta property="article:modified_time" content="2024-06-07T15:57:53.776Z">
<meta property="article:author" content="CARRY">
<meta property="article:tag" content="大模型运用">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/carry121/pictures/raw/master//pictures/20240607235739.png"><link rel="shortcut icon" href="/img/letter-c.png"><link rel="canonical" href="https://delahayecarry.github.io/2024/06/07/lmama-3-first/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体中文","cht_to_chs":"你已切换为简体中文","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-left"},
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【微调大模型llama】 基于llama 3利用自己的数据集微调（1）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-07 23:57:53'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><link rel="stylesheet" type="text/css" href="./css/font.css"><link rel="stylesheet" type="text/css" href="../../../../css/font.css"><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-categories-card@1.0.0/lib/categorybar.css"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.2.0"><link href="https://cdn.bootcss.com/KaTeX/0.11.1/katex.min.css" rel="stylesheet" /></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/qingxuan/"><i class="fa-fw fas fa-heart"></i><span> 青宣</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://gitee.com/carry121/pictures/raw/master//pictures/20240607235739.png')"><nav id="nav"><span id="blog-info"><a href="/" title="CARRY"><span class="site-name">CARRY</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-heartbeat"></i><span> 其他</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/qingxuan/"><i class="fa-fw fas fa-heart"></i><span> 青宣</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【微调大模型llama】 基于llama 3利用自己的数据集微调（1）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-06-07T14:24:09.000Z" title="发表于 2024-06-07 22:24:09">2024-06-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-07T15:57:53.776Z" title="更新于 2024-06-07 23:57:53">2024-06-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%BF%90%E7%94%A8/">大模型运用</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【微调大模型llama】 基于llama 3利用自己的数据集微调（1）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Llama-3介绍"><a href="#Llama-3介绍" class="headerlink" title="Llama 3介绍"></a>Llama 3介绍</h1><p>本次Llama-3的介绍与前两个版本差不多，大量的测试数据和格式化介绍。但Meta特意提到Llama-3使用了掩码和分组查询注意力这两项技术。</p>
<p>目前，大模型领域最流行的Transformer架构的核心功能是自我注意力机制，这是一种用于处理序列数据的技术，可对输入序列中的每个元素进行加权聚合，以捕获元素之间的重要关系。</p>
<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/image-20240607223603516.png" alt="image-20240607223603516" style="zoom:67%;" />

<p>新的 8B 和 70B 参数 Llama 3 模型是 Llama 2 的重大飞跃，并为这些规模的 LLM 模型建立了新的最先进技术。由于预训练和训练后的改进，模型是当今 8B 和 70B 参数规模的最佳模型。我训练后程序的改进大大降低了错误拒绝率，改善了一致性并增加了模型响应的多样性。我们还看到了推理、代码生成和指令跟踪等功能的极大改进，使 Llama 3 更加易于操控。</p>
<h1 id="什么是微调？"><a href="#什么是微调？" class="headerlink" title="什么是微调？"></a>什么是微调？</h1><p><strong>Fine-tuning（微调）</strong>：通过特定领域数据对预训练模型进行针对性优化，以提升其在特定任务上的性能。</p>
<h2 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h2><p>大模型微调是利用特定领域的数据集对已预训练的大模型进行进一步训练的过程。它旨在优化模型在特定任务上的性能，使模型能够更好地适应和完成特定领域的任务。</p>
<h2 id="为什么要微调？"><a href="#为什么要微调？" class="headerlink" title="为什么要微调？"></a>为什么要微调？</h2><h3 id="定制化功能"><a href="#定制化功能" class="headerlink" title="定制化功能"></a>定制化功能</h3><p>微调的核心原因是赋予大模型更加定制化的功能。通用大模型虽然强大，但在特定领域可能表现不佳。通过微调，可以使模型更好地适应特定领域的需求和特征。</p>
<h3 id="领域知识学习"><a href="#领域知识学习" class="headerlink" title="领域知识学习"></a>领域知识学习</h3><p>通过引入特定领域的数据集进行微调，大模型可以学习该领域的知识和语言模式。这有助于模型在特定任务上取得更好的性能。</p>
<h3 id="微调与超参数优化"><a href="#微调与超参数优化" class="headerlink" title="微调与超参数优化"></a>微调与超参数优化</h3><p>微调过程中，超参数的调整至关重要。超参数如学习率、批次大小和训练轮次等需要根据特定任务和数据集进行调整，以确保模型在训练过程中的有效性和性能。</p>
<h1 id="手把手微调llama3-8B模型"><a href="#手把手微调llama3-8B模型" class="headerlink" title="手把手微调llama3-8B模型"></a>手把手微调llama3-8B模型</h1><h2 id="使用的框架和平台介绍"><a href="#使用的框架和平台介绍" class="headerlink" title="使用的框架和平台介绍"></a>使用的框架和平台介绍</h2><p>我将使用的是<code>Unsloth</code>框架来进行模型的微调，利用的平台是官方建议的Colab平台，GPU是T4，显存是22G。<a href="https://github.com/unslothai/unsloth">跳转到Unsloth开源框架</a></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/image-20240607224118153.png" alt="image-20240607224118153"></p>
<p>这样基本条件已经准备好了，我们即将开始微调属于我们的大模型。</p>
<h2 id="利用框架加载模型"><a href="#利用框架加载模型" class="headerlink" title="利用框架加载模型"></a>利用框架加载模型</h2><p>我们来到colab界面后，先连接到runtime中的T4 gpu（当然算力单元要是足够的话可以直接上L4）。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/image-20240607224638626.png" alt="image-20240607224638626"></p>
<p>这样我们的GPU就配置好了，colab自带python3，我们直接开始到拉库。</p>
<p><strong>注意</strong>：安装的包有主要有<code>Unsloth, Xformers (Flash Attention)，torch2.21（cuda），numpy</code>等等。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">%%capture</span><br><span class="line"><span class="comment"># Installs Unsloth, Xformers (Flash Attention) and all other packages!</span></span><br><span class="line">!pip install <span class="string">&quot;unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git&quot;</span></span><br><span class="line">!pip install --no-deps xformers <span class="string">&quot;trl&lt;0.9.0&quot;</span> peft accelerate bitsandbytes</span><br></pre></td></tr></table></figure>

<p>现在我们开始加载模型</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> FastLanguageModel</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line">max_seq_length = <span class="number">2048</span> </span><br><span class="line">dtype = <span class="literal">None</span> </span><br><span class="line">load_in_4bit = <span class="literal">True</span> </span><br><span class="line"></span><br><span class="line">fourbit_models = [</span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-v0.3-bnb-4bit&quot;</span>,      </span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-instruct-v0.3-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-8b-bnb-4bit&quot;</span>,           </span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-8b-Instruct-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/llama-3-70b-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/Phi-3-mini-4k-instruct&quot;</span>,        </span><br><span class="line">    <span class="string">&quot;unsloth/Phi-3-medium-4k-instruct&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/mistral-7b-bnb-4bit&quot;</span>,</span><br><span class="line">    <span class="string">&quot;unsloth/gemma-7b-bnb-4bit&quot;</span>,            </span><br><span class="line">] </span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model, tokenizer = FastLanguageModel.from_pretrained(</span><br><span class="line">    model_name = <span class="string">&quot;unsloth/llama-3-8b-bnb-4bit&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dtype = dtype,</span><br><span class="line">    load_in_4bit = load_in_4bit,</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：</p>
<ol>
<li><code>max_seq_length</code>任选其一，unsloth在内部自动支持 RoPE 扩展。</li>
<li><code>dtype</code>的参数可以给到<code>None</code>，按照官方文档是<code>None</code>就是自动检测。<code>Float16</code>是T4，<code>Bfloat16</code>是安培架构的gpu。</li>
<li>理论上可以微调所有模型，更多模型在<a href="https://huggingface.co/unsloth">https://huggingface.co/unsloth</a> 这里下载。</li>
</ol>
<p>我们现在开始运行一下，得到以下输出：</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.</span><br><span class="line">config.json: 100%</span><br><span class="line"> 1.20k/1.20k [00:00&lt;00:00, 28.6kB/s]</span><br><span class="line">==((====))==  Unsloth: Fast Llama patching release 2024.5</span><br><span class="line">   \\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.</span><br><span class="line">O^O/ \<span class="emphasis">_/ \    Pytorch: 2.3.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.</span></span><br><span class="line"><span class="emphasis">\        /    Bfloat16 = FALSE. Xformers = 0.0.26.post1. FA = False.</span></span><br><span class="line"><span class="emphasis"> &quot;-<span class="strong">____</span>-&quot;     Free Apache license: http://github.com/unslothai/unsloth</span></span><br><span class="line"><span class="emphasis">model.safetensors: 100%</span></span><br><span class="line"><span class="emphasis"> 5.70G/5.70G [00:53&lt;00:00, 26.6MB/s]</span></span><br><span class="line"><span class="emphasis">generation_</span>config.json: 100%</span><br><span class="line"> 172/172 [00:00&lt;00:00, 9.53kB/s]</span><br><span class="line">tokenizer<span class="emphasis">_config.json: 100%</span></span><br><span class="line"><span class="emphasis"> 50.6k/50.6k [00:00&lt;00:00, 2.56MB/s]</span></span><br><span class="line"><span class="emphasis">tokenizer.json: 100%</span></span><br><span class="line"><span class="emphasis"> 9.09M/9.09M [00:00&lt;00:00, 57.4MB/s]</span></span><br><span class="line"><span class="emphasis">special_</span>tokens<span class="emphasis">_map.json: 100%</span></span><br><span class="line"><span class="emphasis"> 464/464 [00:00&lt;00:00, 28.2kB/s]</span></span><br><span class="line"><span class="emphasis">Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.</span></span><br></pre></td></tr></table></figure>

<p>这样我们就做好了模型的加载和训练微调的准备。</p>
<h2 id="利用自己准备的数据集进行微调"><a href="#利用自己准备的数据集进行微调" class="headerlink" title="利用自己准备的数据集进行微调"></a>利用自己准备的数据集进行微调</h2><h3 id="准备数据集"><a href="#准备数据集" class="headerlink" title="准备数据集"></a>准备数据集</h3><p>我准备的数据集，来自yahma的alpaca-cleaned的数据集，以下是部分数据的展示。</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Give three tips for staying healthy.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;1. Eat a balanced and nutritious diet: Make sure your meals are inclusive of a variety of fruits and vegetables, lean protein, whole grains, and healthy fats. This helps to provide your body with the essential nutrients to function at its best and can help prevent chronic diseases.\n\n2. Engage in regular physical activity: Exercise is crucial for maintaining strong bones, muscles, and cardiovascular health. Aim for at least 150 minutes of moderate aerobic exercise or 75 minutes of vigorous exercise each week.\n\n3. Get enough sleep: Getting enough quality sleep is crucial for physical and mental well-being. It helps to regulate mood, improve cognitive function, and supports healthy growth and immune function. Aim for 7-9 hours of sleep each night.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;What are the three primary colors?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The three primary colors are red, blue, and yellow. These colors are called primary because they cannot be created by mixing other colors and all other colors can be made by combining them in various proportions. In the additive color system, used for light, the primary colors are red, green, and blue (RGB).&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Describe the structure of an atom.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;An atom is the basic building block of all matter and is made up of three types of particles: protons, neutrons, and electrons. The structure of an atom can be described as a nucleus at the center surrounded by a cloud of electrons.\n\nThe nucleus of an atom is made up of protons and neutrons. Protons are positively charged particles and neutrons are neutral particles with no charge. Both of these particles are located in the nucleus of the atom, which is at the center of the atom and contains most of the atom&#x27;s mass.\n\nSurrounding the nucleus of the atom is a cloud of electrons. Electrons are negatively charged particles that are in constant motion around the nucleus. The electron cloud is divided into shells or orbitals, and each shell can hold a certain number of electrons. The number of electrons in the outermost shell, called the valence shell, determines the chemical properties of the atom. \n\nIn a neutral atom, the number of protons in the nucleus is equal to the number of electrons in the electron cloud, so the positive and negative charges balance out and the atom has no overall charge. The number of protons, also called the atomic number, determines what element the atom is.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;How can we reduce air pollution?&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;There are several ways to reduce air pollution, including:\n\n1. Reduce energy consumption: By conserving energy, we reduce the amount of pollution emitted from power plants. Some ways to achieve this include: using energy-efficient appliances and lighting, insulating homes, and shutting off lights and electronics when not in use.\n\n2. Use public transportation or carpool: Cars and trucks are major sources of pollution. By using public transportation, carpooling or biking, you can reduce the number of cars on the road, which in turn reduces emissions.\n\n3. Be responsible with waste: When waste is burned or decomposed, they can release harmful gases into the air. Dispose of hazardous waste correctly and recycle materials like plastics, paper, and glass when possible.\n\n4. Support clean energy sources: Renewable energy sources like solar and wind power generate little or no pollution. Support clean energy companies and projects, and consider installing renewable energy systems in your home.\n\n5. Drive efficiently: If you need to drive, make sure your vehicle is well maintained and drive efficiently by avoiding rapid acceleration and braking, and reducing idling.\n\n6. Be mindful of product choices: Some products and practices release more pollution than others. Choose products with eco-friendly packaging and try to minimize your use of aerosol sprays, which can release harmful chemicals into the air.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Pretend you are a project manager of a construction company. Describe a time when you had to make a difficult decision.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;I had to make a difficult decision when I was working as a project manager at a construction company. I was in charge of a project that needed to be completed by a certain date in order to meet the client\u2019s expectations. However, due to unexpected delays, we were not able to meet the deadline and so I had to make a difficult decision. I decided to extend the deadline, but I had to stretch the team\u2019s resources even further and increase the budget. Although it was a risky decision, I ultimately decided to go ahead with it to ensure that the project was completed on time and that the client\u2019s expectations were met. The project was eventually successfully completed and this was seen as a testament to my leadership and decision-making abilities.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Write a concise summary of the following:\n\&quot;Commodore 64 (commonly known as the C64 or CBM 64) was manufactured by Commodore Business Machine (CBM) in August 1982 with a starting price of $595. It was an 8-bit home computer with remarkable market success. Between 1983-1986, C64 sales amounted to about 17 million units sold, making them the best-selling single personal computer model of all time in 1983-1986. \n\nAdditionally, the Commodore 64 dominated the market with between 30% and 40% share and 2 million units sold per year, outselling the IBM PC clones, Apple Computers, and Atari computers. Adding to their success, Sam Tramiel (former Atari president), during an interview in 1989, said they were building 400,000 C64s a month for a couple of years. \&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The Commodore 64 was a highly successful 8-bit home computer manufactured by Commodore Business Machine (CBM) in 1982, with sales amounting to approximately 17 million units sold between 1983-1986. It dominated the market with between 30% and 40% share and outsold its competitors, including IBM PC clones, Apple Computers, and Atari computers. At its peak, CBM was building 400,000 C64s a month for a couple of years.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Explain why the following fraction is equivalent to 1/4&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;4/16&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The fraction 4/16 is equivalent to 1/4 because both fractions represent the same value. A fraction can be simplified by dividing both the numerator and the denominator by a common factor. In this case, 4 is a common factor of both the numerator and the denominator of 4/16. When we divide both by 4, we get 4/4 = 1 and 16/4 = 4, so the simplified fraction is 1/4. Alternatively, we can think of this in terms of multiplication. For example, if we multiply the numerator and denominator of the fraction 1/4 by 4, we get (1x4)/(4x4), or 4/16. Since both fractions can be derived from the other through multiplication or division by the same number, they represent the same value and are equivalent.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Write a short story in third person narration about a protagonist who has to make an important career decision.&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Sophie sat at her desk, staring blankly at the computer screen. Her mind was racing as she weighed the options in front of her. She had been offered a promotion to a senior management position within her company, but it meant moving across the country and leaving her friends and family behind. At the same time, her dream job at a rival company had finally opened up, and she had been invited for an interview. \n\nThe thought of leaving her comfortable life behind, to take a chance on something new and uncertain, made Sophie feel anxious, but also excited. She had always been one to take risks, and it had paid off in the past. But now, with such a big decision to make, Sophie couldn&#x27;t help but feel overwhelmed.\n\nAfter much deliberation, Sophie made her choice. She packed her bags, said goodbye to her loved ones, and moved across the country for the new job. It was a difficult first few months, adjusting to a new city and a new company culture. But as time went by, Sophie realized that she had made the best decision for her career. The job was challenging, but also rewarding, and she was surrounded by passionate, driven colleagues who inspired her to grow and develop.\n\nIn the end, Sophie&#x27;s bold move paid off. She was thriving in her new role, and had made new friends and connections in her new city. Looking back, Sophie was grateful for the opportunity to take a risk and make a change, and was confident that she had made the right decision for her career.&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;instruction&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Evaluate this sentence for spelling and grammar mistakes&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;input&quot;</span><span class="punctuation">:</span> <span class="string">&quot;He finnished his meal and left the resturant&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;output&quot;</span><span class="punctuation">:</span> <span class="string">&quot;There are two spelling errors in the sentence. The corrected sentence should be: \&quot;He finished his meal and left the restaurant.\&quot;&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br></pre></td></tr></table></figure>

<p>这个数据集是json文件，我们可以模仿它制作属于我们自己的数据集，来更好的构建我们需要的知识库系统。</p>
<p>考虑到我们配置的平台和数据集大小，我们只需要更新一下llama3的1%-10%的参数即可。这取决于数据大小，如果数据集大的话需要更新的参数更多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">model = FastLanguageModel.get_peft_model(</span><br><span class="line">    model,</span><br><span class="line">    r = <span class="number">16</span>, <span class="comment"># Choose any number &gt; 0 ! Suggested 8, 16, 32, 64, 128</span></span><br><span class="line">    target_modules = [<span class="string">&quot;q_proj&quot;</span>, <span class="string">&quot;k_proj&quot;</span>, <span class="string">&quot;v_proj&quot;</span>, <span class="string">&quot;o_proj&quot;</span>,</span><br><span class="line">                      <span class="string">&quot;gate_proj&quot;</span>, <span class="string">&quot;up_proj&quot;</span>, <span class="string">&quot;down_proj&quot;</span>,],</span><br><span class="line">    lora_alpha = <span class="number">16</span>,</span><br><span class="line">    lora_dropout = <span class="number">0</span>, <span class="comment"># Supports any, but = 0 is optimized</span></span><br><span class="line">    bias = <span class="string">&quot;none&quot;</span>,    <span class="comment"># Supports any, but = &quot;none&quot; is optimized</span></span><br><span class="line">    <span class="comment"># [NEW] &quot;unsloth&quot; uses 30% less VRAM, fits 2x larger batch sizes!</span></span><br><span class="line">    use_gradient_checkpointing = <span class="string">&quot;unsloth&quot;</span>, <span class="comment"># True or &quot;unsloth&quot; for very long context</span></span><br><span class="line">    random_state = <span class="number">3407</span>,</span><br><span class="line">    use_rslora = <span class="literal">False</span>,  <span class="comment"># We support rank stabilized LoRA</span></span><br><span class="line">    loftq_config = <span class="literal">None</span>, <span class="comment"># And LoftQ</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>注意</strong>：</p>
<ol>
<li><p><code>r = 16</code>必须填写大于0的整数，最好是2的n次方。</p>
</li>
<li><p><code>lora_dropout</code>它的参数表示以这个<code>dropout</code>的概率来随机选择忽略的神经元来避免过拟合，最好写0。</p>
<p>具体LORA原理请看<a href="https://zhuanlan.zhihu.com/p/664664239">这篇文章</a>，我这里不展开了。</p>
</li>
</ol>
<h3 id="预处理数据"><a href="#预处理数据" class="headerlink" title="预处理数据"></a>预处理数据</h3><p>做一个数据的分割，保证能够将数据集中的每个示例按照特定的格式进行处理，这样才能将这个数据集用于自然语言生成模型，例如llama3。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">alpaca_prompt = </span><br><span class="line"></span><br><span class="line">EOS_TOKEN = tokenizer.eos_token <span class="comment"># Must add EOS_TOKEN</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">formatting_prompts_func</span>(<span class="params">examples</span>):</span><br><span class="line">    instructions = examples[<span class="string">&quot;instruction&quot;</span>]</span><br><span class="line">    inputs       = examples[<span class="string">&quot;input&quot;</span>]</span><br><span class="line">    outputs      = examples[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    texts = []</span><br><span class="line">    <span class="keyword">for</span> instruction, <span class="built_in">input</span>, output <span class="keyword">in</span> <span class="built_in">zip</span>(instructions, inputs, outputs):</span><br><span class="line">        <span class="comment"># Must add EOS_TOKEN, otherwise your generation will go on forever!</span></span><br><span class="line">        text = alpaca_prompt.<span class="built_in">format</span>(instruction, <span class="built_in">input</span>, output) + EOS_TOKEN</span><br><span class="line">        texts.append(text)</span><br><span class="line">    <span class="keyword">return</span> &#123; <span class="string">&quot;text&quot;</span> : texts, &#125;</span><br><span class="line"><span class="keyword">pass</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>处理完立刻加载：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line">dataset = load_dataset(<span class="string">&quot;yahma/alpaca-cleaned&quot;</span>, split = <span class="string">&quot;train&quot;</span>)</span><br><span class="line">dataset = dataset.<span class="built_in">map</span>(formatting_prompts_func, batched = <span class="literal">True</span>,)</span><br></pre></td></tr></table></figure>

<p>数据集准备完毕后我们直接开始微调。</p>
<h2 id="微调开始"><a href="#微调开始" class="headerlink" title="微调开始"></a>微调开始</h2><p>按照官方文档设定好预训练模型和默认超参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> trl <span class="keyword">import</span> SFTTrainer</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> TrainingArguments</span><br><span class="line"><span class="keyword">from</span> unsloth <span class="keyword">import</span> is_bfloat16_supported</span><br><span class="line"></span><br><span class="line">trainer = SFTTrainer(</span><br><span class="line">    model = model,</span><br><span class="line">    tokenizer = tokenizer,</span><br><span class="line">    train_dataset = dataset,</span><br><span class="line">    dataset_text_field = <span class="string">&quot;text&quot;</span>,</span><br><span class="line">    max_seq_length = max_seq_length,</span><br><span class="line">    dataset_num_proc = <span class="number">2</span>,</span><br><span class="line">    packing = <span class="literal">False</span>, <span class="comment"># Can make training 5x faster for short sequences.</span></span><br><span class="line">    args = TrainingArguments(</span><br><span class="line">        per_device_train_batch_size = <span class="number">2</span>,</span><br><span class="line">        gradient_accumulation_steps = <span class="number">4</span>,</span><br><span class="line">        warmup_steps = <span class="number">5</span>,</span><br><span class="line">        max_steps = <span class="number">60</span>,</span><br><span class="line">        learning_rate = <span class="number">2e-4</span>,</span><br><span class="line">        fp16 = <span class="keyword">not</span> is_bfloat16_supported(),</span><br><span class="line">        bf16 = is_bfloat16_supported(),</span><br><span class="line">        logging_steps = <span class="number">1</span>,</span><br><span class="line">        optim = <span class="string">&quot;adamw_8bit&quot;</span>,</span><br><span class="line">        weight_decay = <span class="number">0.01</span>,</span><br><span class="line">        lr_scheduler_type = <span class="string">&quot;linear&quot;</span>,</span><br><span class="line">        seed = <span class="number">3407</span>,</span><br><span class="line">        output_dir = <span class="string">&quot;outputs&quot;</span>,</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>基本超参数我就不介绍了，基本按照默认。</p>
<p>得到输出结果</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">/usr/local/lib/python3.10/dist-packages/multiprocess/popen<span class="emphasis">_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.</span></span><br><span class="line"><span class="emphasis">  self.pid = os.fork()</span></span><br><span class="line"><span class="emphasis">Map (num_</span>proc=2): 100%</span><br><span class="line"> 51760/51760 [00:53&lt;00:00, 1987.81 examples/s]</span><br><span class="line">max<span class="emphasis">_steps is given, it will override any value given in num_</span>train<span class="emphasis">_epochs</span></span><br></pre></td></tr></table></figure>

<p>打印一下gpu信息，确保gpu配置正确。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gpu_stats = torch.cuda.get_device_properties(<span class="number">0</span>)</span><br><span class="line">start_gpu_memory = <span class="built_in">round</span>(torch.cuda.max_memory_reserved() / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line">max_memory = <span class="built_in">round</span>(gpu_stats.total_memory / <span class="number">1024</span> / <span class="number">1024</span> / <span class="number">1024</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;GPU = <span class="subst">&#123;gpu_stats.name&#125;</span>. Max memory = <span class="subst">&#123;max_memory&#125;</span> GB.&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;start_gpu_memory&#125;</span> GB of memory reserved.&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>得到</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">GPU = Tesla T4. Max memory = 14.748 GB.</span><br><span class="line">5.594 GB of memory reserved.</span><br></pre></td></tr></table></figure>

<p>说明我的gpu配置正确。</p>
<p>那么直接开始训练：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer_stats = trainer.train()</span><br></pre></td></tr></table></figure>

<p>经过几分钟后，我得到训练的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line">==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1</span><br><span class="line">   \\   /|    Num examples = 51,760 | Num Epochs = 1</span><br><span class="line">O^O/ \_/ \    Batch size per device = 2 | Gradient Accumulation steps = 4</span><br><span class="line">\        /    Total batch size = 8 | Total steps = 60</span><br><span class="line"> &quot;-____-&quot;     Number of trainable parameters = 41,943,040</span><br><span class="line"> [22/60 02:20 &lt; 04:26, 0.14 it/s, Epoch 0.00/1]</span><br><span class="line">Step	Training Loss</span><br><span class="line">1	1.814500</span><br><span class="line">2	2.285700</span><br><span class="line">3	1.687500</span><br><span class="line">4	1.941200</span><br><span class="line">5	1.638300</span><br><span class="line">6	1.596200</span><br><span class="line">7	1.187800</span><br><span class="line">8	1.252300</span><br><span class="line">9	1.100100</span><br><span class="line">10	1.159300</span><br><span class="line">11	0.960700</span><br><span class="line">12	1.000500</span><br><span class="line">13	0.932200</span><br><span class="line">14	1.056200</span><br><span class="line">15	0.906500</span><br><span class="line">16	0.909100</span><br><span class="line">17	1.021500</span><br><span class="line">18	1.281200</span><br><span class="line">19	1.011400</span><br><span class="line">20	0.898900</span><br><span class="line"> [60/60 07:18, Epoch 0/1]</span><br><span class="line">Step	Training Loss</span><br><span class="line">1	1.814500</span><br><span class="line">2	2.285700</span><br><span class="line">3	1.687500</span><br><span class="line">4	1.941200</span><br><span class="line">5	1.638300</span><br><span class="line">6	1.596200</span><br><span class="line">7	1.187800</span><br><span class="line">8	1.252300</span><br><span class="line">9	1.100100</span><br><span class="line">10	1.159300</span><br><span class="line">11	0.960700</span><br><span class="line">12	1.000500</span><br><span class="line">13	0.932200</span><br><span class="line">14	1.056200</span><br><span class="line">15	0.906500</span><br><span class="line">16	0.909100</span><br><span class="line">17	1.021500</span><br><span class="line">18	1.281200</span><br><span class="line">19	1.011400</span><br><span class="line">20	0.898900</span><br><span class="line">21	0.947400</span><br><span class="line">22	1.014800</span><br><span class="line">23	0.883300</span><br><span class="line">24	0.993200</span><br><span class="line">25	1.065700</span><br><span class="line">26	1.009700</span><br><span class="line">27	1.039500</span><br><span class="line">28	0.872200</span><br><span class="line">29	0.840000</span><br><span class="line">30	0.901700</span><br><span class="line">31	0.867100</span><br><span class="line">32	0.864300</span><br><span class="line">33	0.985000</span><br><span class="line">34	0.859700</span><br><span class="line">35	0.962900</span><br><span class="line">36	0.859900</span><br><span class="line">37	0.885800</span><br><span class="line">38	0.766800</span><br><span class="line">39	1.083200</span><br><span class="line">40	1.159200</span><br><span class="line">41	0.903300</span><br><span class="line">42	0.985700</span><br><span class="line">43	0.960600</span><br><span class="line">44	0.899200</span><br><span class="line">45	0.921800</span><br><span class="line">46	0.998700</span><br><span class="line">47	0.865800</span><br><span class="line">48	1.215900</span><br><span class="line">49	0.910900</span><br><span class="line">50	1.046900</span><br><span class="line">51	1.019400</span><br><span class="line">52	0.922700</span><br><span class="line">53	1.002500</span><br><span class="line">54	1.168000</span><br><span class="line">55	0.797800</span><br><span class="line">56	1.026400</span><br><span class="line">57	0.884300</span><br><span class="line">58	0.826800</span><br><span class="line">59	0.861400</span><br><span class="line">60	0.904500</span><br></pre></td></tr></table></figure>

<p>可以看到80个周期后，loss已经收敛了，那么我们基本的训练就完成了。</p>
<p>我们打印一下显存消耗和时间消耗：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">452.6049 seconds used for training.</span><br><span class="line">7.54 minutes used for training.</span><br><span class="line">Peak reserved memory = 7.535 GB.</span><br><span class="line">Peak reserved memory for training = 1.941 GB.</span><br><span class="line">Peak reserved memory % of max memory = 51.092 %.</span><br><span class="line">Peak reserved memory for training % of max memory = 13.161 %.</span><br></pre></td></tr></table></figure>

<p>现在开始测试一下模型。</p>
<p>我这里使用提示词是菲利波数列的前几位，我想让我的模型续写。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/image-20240607233712185.png" alt="image-20240607233712185"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># alpaca_prompt = Copied from above</span></span><br><span class="line">FastLanguageModel.for_inference(model) <span class="comment"># Enable native 2x faster inference</span></span><br><span class="line">inputs = tokenizer(</span><br><span class="line">[</span><br><span class="line">    alpaca_prompt.<span class="built_in">format</span>(</span><br><span class="line">        <span class="string">&quot;Continue the fibonnaci sequence.&quot;</span>, <span class="comment"># instruction</span></span><br><span class="line">        <span class="string">&quot;1, 1, 2, 3, 5, 8&quot;</span>, <span class="comment"># input</span></span><br><span class="line">        <span class="string">&quot;&quot;</span>, <span class="comment"># output - leave this blank for generation!</span></span><br><span class="line">    )</span><br><span class="line">], return_tensors = <span class="string">&quot;pt&quot;</span>).to(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line"></span><br><span class="line">outputs = model.generate(**inputs, max_new_tokens = <span class="number">64</span>, use_cache = <span class="literal">True</span>)</span><br><span class="line">tokenizer.batch_decode(outputs)</span><br></pre></td></tr></table></figure>

<p><strong>注意：</strong>一定要按照数据集的格式来输入!!!</p>
<p>我得到了它的回复：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.</span><br><span class="line">[&#x27;&lt;|begin_of_text|&gt;Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n### Instruction:\nContinue the fibonnaci sequence.\n\n### Input:\n1, 1, 2, 3, 5, 8\n\n### Response:\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987&lt;|end_of_text|&gt;&#x27;]</span><br></pre></td></tr></table></figure>

<p><code>Response:\n13, 21, 34, 55, 89, 144, 233, 377, 610, 987&lt;|end_of_text|&gt;&#39;]</code></p>
<p>可以看到我们已经得到了答案，确实是正确的。</p>
<p>具体测试和新数据集的微调我将在下一篇文章介绍。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://Delahayecarry.github.io">CARRY</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://delahayecarry.github.io/2024/06/07/lmama-3-first/">https://delahayecarry.github.io/2024/06/07/lmama-3-first/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://Delahayecarry.github.io" target="_blank">CARRY</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%BF%90%E7%94%A8/">大模型运用</a></div><div class="post_share"><div class="social-share" data-image="https://gitee.com/carry121/pictures/raw/master//pictures/20240607235739.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/06/08/llama3-2-dataprep/" title="【Llama3数据集准备】适用于llama3个人数据集的制作"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240608125209.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【Llama3数据集准备】适用于llama3个人数据集的制作</div></div></a></div><div class="next-post pull-right"><a href="/2024/05/26/rnn-lstm/" title="【RNN ＆ LTSM】"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240526215503.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【RNN ＆ LTSM】</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/07/20/Graphrag-2/" title="【Graphrag】GR框架检索和webui化"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240720170332.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-20</div><div class="title">【Graphrag】GR框架检索和webui化</div></div></a></div><div><a href="/2024/09/23/NEw/" title="利用Prompt实现推理链"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-23</div><div class="title">利用Prompt实现推理链</div></div></a></div><div><a href="/2024/07/18/graphrag-1/" title="【GraphRag】以知识图谱的方式建立知识库系统"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240804163439.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-07-18</div><div class="title">【GraphRag】以知识图谱的方式建立知识库系统</div></div></a></div><div><a href="/2024/06/08/llama3-2-dataprep/" title="【Llama3数据集准备】适用于llama3个人数据集的制作"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240608125209.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-06-08</div><div class="title">【Llama3数据集准备】适用于llama3个人数据集的制作</div></div></a></div><div><a href="/2024/05/11/local-llm-in-autogen/" title="【Llmba 3离线部署+lm studio】实现Autogen离线部署"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240511104831.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-05-11</div><div class="title">【Llmba 3离线部署+lm studio】实现Autogen离线部署</div></div></a></div><div><a href="/2024/09/27/visual-graphRag/" title="可视化GraphRag节点和社区"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-09-27</div><div class="title">可视化GraphRag节点和社区</div></div></a></div></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CARRY</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">8</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" href="https://github.com/Delahayecarry"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Delahayecarry" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:Delahayecarry@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客!现在分类是按照技术栈分类，方便互相学习！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Llama-3%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">Llama 3介绍</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E8%B0%83%EF%BC%9F"><span class="toc-number">2.</span> <span class="toc-text">什么是微调？</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">2.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%BE%AE%E8%B0%83%EF%BC%9F"><span class="toc-number">2.2.</span> <span class="toc-text">为什么要微调？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E5%88%B6%E5%8C%96%E5%8A%9F%E8%83%BD"><span class="toc-number">2.2.1.</span> <span class="toc-text">定制化功能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%86%E5%9F%9F%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.2.2.</span> <span class="toc-text">领域知识学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E4%B8%8E%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96"><span class="toc-number">2.2.3.</span> <span class="toc-text">微调与超参数优化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%89%8B%E6%8A%8A%E6%89%8B%E5%BE%AE%E8%B0%83llama3-8B%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.</span> <span class="toc-text">手把手微调llama3-8B模型</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%9A%84%E6%A1%86%E6%9E%B6%E5%92%8C%E5%B9%B3%E5%8F%B0%E4%BB%8B%E7%BB%8D"><span class="toc-number">3.1.</span> <span class="toc-text">使用的框架和平台介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E6%A1%86%E6%9E%B6%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.2.</span> <span class="toc-text">利用框架加载模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E8%87%AA%E5%B7%B1%E5%87%86%E5%A4%87%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E5%BE%AE%E8%B0%83"><span class="toc-number">3.3.</span> <span class="toc-text">利用自己准备的数据集进行微调</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.3.1.</span> <span class="toc-text">准备数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE"><span class="toc-number">3.3.2.</span> <span class="toc-text">预处理数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E5%BC%80%E5%A7%8B"><span class="toc-number">3.4.</span> <span class="toc-text">微调开始</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/27/visual-graphRag/" title="可视化GraphRag节点和社区">可视化GraphRag节点和社区</a><time datetime="2024-09-27T09:28:53.000Z" title="发表于 2024-09-27 17:28:53">2024-09-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/09/23/NEw/" title="利用Prompt实现推理链">利用Prompt实现推理链</a><time datetime="2024-09-23T13:26:57.000Z" title="发表于 2024-09-23 21:26:57">2024-09-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/08/23/ominiparse/" title="【MAGIC-PDF】OCR扫描实现PDF2Md">【MAGIC-PDF】OCR扫描实现PDF2Md</a><time datetime="2024-08-23T08:24:09.000Z" title="发表于 2024-08-23 16:24:09">2024-08-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/20/Graphrag-2/" title="【Graphrag】GR框架检索和webui化"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240720170332.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【Graphrag】GR框架检索和webui化"/></a><div class="content"><a class="title" href="/2024/07/20/Graphrag-2/" title="【Graphrag】GR框架检索和webui化">【Graphrag】GR框架检索和webui化</a><time datetime="2024-07-20T07:54:09.000Z" title="发表于 2024-07-20 15:54:09">2024-07-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/18/graphrag-1/" title="【GraphRag】以知识图谱的方式建立知识库系统"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://gitee.com/carry121/pictures/raw/master//pictures/20240804163439.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【GraphRag】以知识图谱的方式建立知识库系统"/></a><div class="content"><a class="title" href="/2024/07/18/graphrag-1/" title="【GraphRag】以知识图谱的方式建立知识库系统">【GraphRag】以知识图谱的方式建立知识库系统</a><time datetime="2024-07-18T14:32:07.000Z" title="发表于 2024-07-18 22:32:07">2024-07-18</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://gitee.com/carry121/pictures/raw/master//pictures/20240607235739.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By CARRY</div><div class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.8.8/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar@0.1.16/dist/snackbar.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/copy-tex.min.js"></script><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(() => {
  const getCount = () => {
    const countELement = document.getElementById('twikoo-count')
    if(!countELement) return
    twikoo.getCommentsCount({
      envId: 'https://twikoo.delahayecarry.cn/',
      region: 'AWS / N. Virginia (us-east-1)',
      urls: [window.location.pathname],
      includeReply: false
    }).then(res => {
      countELement.textContent = res[0].count
    }).catch(err => {
      console.error(err)
    })
  }

  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo.delahayecarry.cn/',
      region: 'AWS / N. Virginia (us-east-1)',
      onCommentLoaded: () => {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.tk-owo-emotion)'))
      }
    }, null))

    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') setTimeout(init,0)
    else getScript('https://cdn.jsdelivr.net/npm/twikoo@1.6.31/dist/twikoo.all.min.js').then(init)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = loadTwikoo
  }
})()</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1.10.1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/metingjs/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
    function butterfly_categories_card_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<style>li.categoryBar-list-item{width:32.3%;}.categoryBar-list{max-height: 190px;overflow:auto;}.categoryBar-list::-webkit-scrollbar{width:0!important}@media screen and (max-width: 650px){.categoryBar-list{max-height: 160px;}}</style><div class="recent-post-item" style="height:auto;width:100%;padding:0px;"><div id="categoryBar"><ul class="categoryBar-list"><li class="categoryBar-list-item" style="background:url(https://p4.music.126.net/eAG-_g4t7mmIdZQO1PsXBA==/109951164483215843.jpg);"> <a class="categoryBar-list-link" href="categories/大模型运用/">大模型运用</a><span class="categoryBar-list-count">7</span><span class="categoryBar-list-descr">大模型运用</span></li><li class="categoryBar-list-item" style="background:url(https://p3.music.126.net/7f3bD3eEmz0KjRLuqsLV9g==/109951165718240862.jpg);"> <a class="categoryBar-list-link" href="categories/深度学习/">深度学习</a><span class="categoryBar-list-count">4</span><span class="categoryBar-list-descr">学习</span></li><li class="categoryBar-list-item" style="background:url(https://p3.music.126.net/NSSWXe7_mlbKpaM9sg5A6w==/109951168785989827.jpg);"> <a class="categoryBar-list-link" href="categories/机器学习算法/">机器学习算法</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">爬虫</span></li><li class="categoryBar-list-item" style="background:url(https://p4.music.126.net/mAUiNEfKqPe230qptWd6uA==/109951168988739342.jpg);"> <a class="categoryBar-list-link" href="categories/学习/">学习</a><span class="categoryBar-list-count">2</span><span class="categoryBar-list-descr">个人日记</span></li><li class="categoryBar-list-item" style="background:url(https://p3.music.126.net/EJHZAe8C3yYCSgba2oqnjw==/109951169445772816.jpg);"> <a class="categoryBar-list-link" href="categories/爬虫/">爬虫</a><span class="categoryBar-list-count">1</span><span class="categoryBar-list-descr">留给青宣</span></li></ul></div></div>';
      console.log('已挂载butterfly_categories_card')
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      }
    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    butterfly_categories_card_injector_config()
    }
  </script><!-- hexo injector body_end end --></body></html>